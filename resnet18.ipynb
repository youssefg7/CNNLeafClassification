{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 990 images in the dataset\n",
      "There are 99 labels in the dataset\n"
     ]
    }
   ],
   "source": [
    "trainSet = pd.read_csv('Dataset/train.csv')\n",
    "classes = trainSet[['id','species']].copy()\n",
    "classes['id'] = classes['id'].astype(str)\n",
    "classes['label'] = LabelEncoder().fit_transform(classes['species'])\n",
    "\n",
    "image_folder = 'Dataset/images/'\n",
    "imgs = []\n",
    "labels = []\n",
    "for i in sorted(os.listdir(image_folder)):\n",
    "    id = i.split('.')[0]\n",
    "    if id in classes['id'].values:\n",
    "        labels.append(classes[classes['id'] == id]['label'].values[0])\n",
    "        image = Image.open(os.path.join(image_folder, i)).convert('1')\n",
    "        imgs.append(image)\n",
    "\n",
    "print(f\"There are {len(imgs)} images in the dataset\")\n",
    "print(f\"There are {len(np.unique(labels))} labels in the dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 792 images in the training set\n",
      "There are 198 images in the test set\n",
      "There are 99 classes in the training set\n",
      "There are 99 classes in the test set\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "print(f\"There are {len(X_train)} images in the training set\")\n",
    "print(f\"There are {len(X_test)} images in the test set\")\n",
    "print(f\"There are {len(np.unique(y_train))} classes in the training set\")\n",
    "print(f\"There are {len(np.unique(y_test))} classes in the test set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.transform(image=np.array(self.images[index],dtype=np.float32))['image']\n",
    "        label = torch.tensor(self.labels[index], dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "    \n",
    "transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "trainDataSet = CustomDataSet(images=X_train, labels=y_train, transform=transform)\n",
    "testDataSet = CustomDataSet(images=X_test, labels=y_test, transform=transform)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youssefgeorge/.pyenv/versions/3.9.18/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/youssefgeorge/.pyenv/versions/3.9.18/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/1000: 100%|██████████| 13/13 [00:48<00:00,  3.77s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000  Loss: 0.0567, Val Loss: 0.9596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000: 100%|██████████| 13/13 [00:50<00:00,  3.85s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/1000  Loss: 0.0236, Val Loss: 0.8990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000: 100%|██████████| 13/13 [00:50<00:00,  3.85s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/1000  Loss: 0.0104, Val Loss: 0.4697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000: 100%|██████████| 13/13 [00:49<00:00,  3.84s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/1000  Loss: 0.0045, Val Loss: 0.3384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000: 100%|██████████| 13/13 [00:49<00:00,  3.80s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/1000  Loss: 0.0020, Val Loss: 0.2828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000: 100%|██████████| 13/13 [00:50<00:00,  3.92s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/1000  Loss: 0.0010, Val Loss: 0.1566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000: 100%|██████████| 13/13 [00:51<00:00,  3.93s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/1000  Loss: 0.0005, Val Loss: 0.1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000: 100%|██████████| 13/13 [00:50<00:00,  3.89s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/1000  Loss: 0.0003, Val Loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000: 100%|██████████| 13/13 [00:51<00:00,  4.00s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/1000  Loss: 0.0002, Val Loss: 0.1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000: 100%|██████████| 13/13 [00:50<00:00,  3.86s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/1000  Loss: 0.0001, Val Loss: 0.1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000: 100%|██████████| 13/13 [00:49<00:00,  3.79s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/1000  Loss: 0.0001, Val Loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000: 100%|██████████| 13/13 [00:49<00:00,  3.78s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/1000  Loss: 0.0001, Val Loss: 0.1263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000: 100%|██████████| 13/13 [00:48<00:00,  3.74s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/1000  Loss: 0.0001, Val Loss: 0.1212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000: 100%|██████████| 13/13 [00:48<00:00,  3.72s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/1000  Loss: 0.0000, Val Loss: 0.1212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000: 100%|██████████| 13/13 [00:48<00:00,  3.71s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/1000  Loss: 0.0000, Val Loss: 0.1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000: 100%|██████████| 13/13 [00:48<00:00,  3.74s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/1000  Loss: 0.0000, Val Loss: 0.1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000: 100%|██████████| 13/13 [00:48<00:00,  3.75s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/1000  Loss: 0.0000, Val Loss: 0.1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000: 100%|██████████| 13/13 [00:48<00:00,  3.75s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/1000  Loss: 0.0000, Val Loss: 0.1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000: 100%|██████████| 13/13 [00:48<00:00,  3.76s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/1000  Loss: 0.0000, Val Loss: 0.1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000: 100%|██████████| 13/13 [00:48<00:00,  3.76s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/1000  Loss: 0.0000, Val Loss: 0.1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/1000: 100%|██████████| 13/13 [00:49<00:00,  3.82s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/1000  Loss: 0.0000, Val Loss: 0.1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000: 100%|██████████| 13/13 [00:49<00:00,  3.77s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/1000  Loss: 0.0000, Val Loss: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000: 100%|██████████| 13/13 [00:51<00:00,  3.99s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/1000  Loss: 0.0000, Val Loss: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000: 100%|██████████| 13/13 [00:48<00:00,  3.71s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/1000  Loss: 0.0000, Val Loss: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000: 100%|██████████| 13/13 [00:49<00:00,  3.77s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/1000  Loss: 0.0000, Val Loss: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000: 100%|██████████| 13/13 [00:48<00:00,  3.75s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/1000  Loss: 0.0000, Val Loss: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000: 100%|██████████| 13/13 [00:49<00:00,  3.77s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/1000  Loss: 0.0000, Val Loss: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000: 100%|██████████| 13/13 [00:48<00:00,  3.75s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/1000  Loss: 0.0000, Val Loss: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/1000: 100%|██████████| 13/13 [00:48<00:00,  3.76s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/1000  Loss: 0.0000, Val Loss: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/1000: 100%|██████████| 13/13 [00:48<00:00,  3.75s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/1000  Loss: 0.0000, Val Loss: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/1000: 100%|██████████| 13/13 [00:49<00:00,  3.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/1000  Loss: 0.0000, Val Loss: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/1000: 100%|██████████| 13/13 [00:49<00:00,  3.83s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/1000  Loss: 0.0000, Val Loss: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/1000: 100%|██████████| 13/13 [00:48<00:00,  3.73s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33/1000  Loss: 0.0000, Val Loss: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/1000: 100%|██████████| 13/13 [00:48<00:00,  3.75s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/1000  Loss: 0.0000, Val Loss: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/1000: 100%|██████████| 13/13 [00:50<00:00,  3.86s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35/1000  Loss: 0.0000, Val Loss: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000: 100%|██████████| 13/13 [00:48<00:00,  3.75s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/1000  Loss: 0.0000, Val Loss: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000: 100%|██████████| 13/13 [00:48<00:00,  3.76s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/1000  Loss: 0.0000, Val Loss: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/1000: 100%|██████████| 13/13 [00:48<00:00,  3.75s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38/1000  Loss: 0.0000, Val Loss: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/1000: 100%|██████████| 13/13 [00:49<00:00,  3.77s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/1000  Loss: 0.0000, Val Loss: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/1000: 100%|██████████| 13/13 [00:49<00:00,  3.77s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40/1000  Loss: 0.0000, Val Loss: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/1000: 100%|██████████| 13/13 [00:48<00:00,  3.76s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/1000  Loss: 0.0000, Val Loss: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/1000: 100%|██████████| 13/13 [00:49<00:00,  3.80s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/1000  Loss: 0.0000, Val Loss: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000:   8%|▊         | 1/13 [00:09<01:48,  9.01s/batch]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Volumes/D/Uni/Semester 9/CSE485 Deep Learning/Project/resnet18.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/D/Uni/Semester%209/CSE485%20Deep%20Learning/Project/resnet18.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(images)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/D/Uni/Semester%209/CSE485%20Deep%20Learning/Project/resnet18.ipynb#W4sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Volumes/D/Uni/Semester%209/CSE485%20Deep%20Learning/Project/resnet18.ipynb#W4sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/D/Uni/Semester%209/CSE485%20Deep%20Learning/Project/resnet18.ipynb#W4sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/D/Uni/Semester%209/CSE485%20Deep%20Learning/Project/resnet18.ipynb#W4sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.18/lib/python3.9/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.18/lib/python3.9/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "trainDataLoader = torch.utils.data.DataLoader(trainDataSet, batch_size=batch_size)\n",
    "testDataLoader = torch.utils.data.DataLoader(testDataSet, batch_size=batch_size)\n",
    "\n",
    "min_loss_epoch = 0\n",
    "min_loss_value = -1\n",
    "best_model_weights_paths = {}\n",
    "\n",
    "best_val_loss = float('inf')  # Initialize with a large value\n",
    "best_epoch = -1\n",
    "best_model_weights = None\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 99)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(trainDataLoader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(trainDataLoader) / batch_size\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()  \n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testDataLoader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    val_loss = 1-accuracy\n",
    "    val_losses.append(val_loss)\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}  Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "best_epoch = val_losses.index(min(val_losses))\n",
    "min_loss_epoch = best_epoch\n",
    "min_loss_value = f'{min(val_losses):.4f}'\n",
    "print(f\"Min Train Loss: {min(train_losses)} at Epoch {train_losses.index(min(train_losses))}  Min Val Loss: {min_loss_value[criterion]} at Epoch {best_epoch}\")\n",
    "\n",
    "\n",
    "# Save the best model's weights\n",
    "torch.save(model, f\"best_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
